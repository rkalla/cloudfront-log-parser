Amazon CloudFront Log Parser
http://www.thebuzzmedia.com/software/cloudfront-log-parser/


Changelog
---------
1.3
	* Improved performance by using new feature in tbm-common-parser-lib that
	allows a tokenizer to re-use the same IToken for every token event instead
	of creating a new one.
	
1.2	
	* More secure exception handling inside of Parse ensures cleanup of any 
	temporary input streams.
	
	* Improved the exception semantics of the parse method.
	https://github.com/thebuzzmedia/cloudfront-log-parser/issues/2
	
	* Parser is more verbal with MalformedContentException errors when the content
	of the log file doesn't match the Amazon-defined DOWNLOAD or STREAMING 
	CloudFront log formats.
	https://github.com/thebuzzmedia/cloudfront-log-parser/issues/2
	
	* Fixed incorrect bounds check for insertion of fields beyond what ILogEntry
	will allow.
	https://github.com/thebuzzmedia/cloudfront-log-parser/issues/5
	
	* Fixed a handful of "tightening" bugs that didn't break the parser previously
	but could lead to leaks or bugs down the road.
	 
	* Addition Javadoc to the source was added to make it more clear what certain
	constructs are for.
	
	* Added a new file to the benchmark that matches a worst-case-scenario log
	file from CloudFront (50MB uncompressed, ~174k entries)
	
	* Added library to The Buzz Media's Maven repo.

1.1
	* Initial public release.


License
-------
This library is released under the Apache 2 License. See LICENSE.


Description
-----------
CloudFront Log Parser is a Java library offering a simple, high-performance and 
adaptive log parser for both the Download and Streaming CloudFront log formats.

The simplicity and adaptivity of the CloudFront Log Parser comes from the 
following two features of the library:

	* Auto-detection of the log format at parse-time.
	* Ability to detect and ignore (until support is added) new or corrupt field 
	names and values that Amazon may add.

#1 makes the library easy to use (a single LogParser class) and #2 makes the 
library safe to deploy in long-running environments (e.g. a log-processing server) 
without worrying that one day Amazon may roll out a change to the log format and 
suddenly your log-processing server is throwing so many exceptions the VM halts.

The CloudFront Log Parser API was designed to be simple to use and flexible 
enough to plug into any use-case. The LogParser class itself consumes raw 
InputStreams from the .gz log files. No need to wrap the streams with buffers or 
worry about them being local or remote resources; the parser doesn't care.

Because of this design, the CloudFront Log Parser integrates really easily with 
Amazon's existing AWS Java SDK as the library can consume the InputStreams coming 
directly from the S3 API's S3Object.getObjectContent() method.

The CloudFront Log Parser is intended to be used in any deployment scenario.


What Problem Does this Solve?
-----------------------------
Amazon promotes the use of their Elastic MapReduce product for processing 
CloudFront logs, which is a good suggestion if you don't mind incurring the 
additional cost of using more AWS services.

For folks wanting to parse the logs themselves (e.g. they already have a server 
available) there are not (any?) Java-based solutions online and hand-writing a 
log parser that is efficient and tightened up correctly so it can run unhindered 
in a headless environment without stopping is not a simple thing to knock out 
in an afternoon.

The CloudFront Log Parser Java Library solves that problem by providing an 
extremely fast and simple-to-integrate library meant to make parsing CloudFront 
log files easy.


Performance
-----------
Benchmarks can be found in the /src/test/java folder of the source tree and
can be run directly from the command line.

[Platform]
* Java 1.6.0_24 on Windows 7 64-bit 
* Dual Core Intel E6850 processor
* 8 GB of ram

[Benchmark Results]
Parsed 100 Log Entries in 27ms (3703 entries / sec)
Parsed 100,000 Log Entries in 864ms (115740 entries / sec)
Parsed 174,200 Log Entries in 1341ms (129903 entries / sec)
Parsed 1,000,000 Log Entries in 7520ms (132978 entries / sec)

The Amazon CloudFront docs say log files are truncated at a maximum size of 50MB 
(uncompressed) before they are written out to the log directory. The 3rd test, 
parsing the 174k log entries is exactly 50MB uncompressed and matches this 
worst-case-scenario. That means using the CloudFront Log Parser Java Library, 
you can parse a 50MB log file in a little over a second on equivalent hardware.

If you are running on faster server hardware your single-threaded rate will be 
higher than what you see here. If you decide to parse logs in a heavily-threaded 
environment (1 LogParser instance per Thread) then your parse rates could be 
magnitudes times faster.

The CloudFront Log Parser Java Library was engineered to be very efficient.


Design
-----------
CloudFront Log Parser was designed, first and foremost, to execute as fast as 
possible with as little memory allocation as possible to avoid thrashing the 
host VM running it. It was designed from the ground up to be effective at parsing 
huge volumes of log entries.

Object creation is kept to a minimum during parsing (no matter how big or long 
the parse operation) by re-using a single ILogEntry instance (either DownloadLogEntry 
or StreamingLogEntry depending on the log type), per LogParser instance. The 
ILogEntry instance is re-used every time a log entry line is parsed and 
delivered to the caller-provided ILogParserCallback instead of creating a new 
ILogEntry instance every single time.

The trade-off for this performance optimization is that the ILogEntry instances 
are volatile. The instance is valid for the scope of the call to the callback, 
but once that callback method returns, the ILogEntry is reused by the parser and 
values inside of it reset and re-populated.

ILogParserCallback implementations should never hold onto ILogEntry instances. 
Pull the values out of them, store/process/manipulate those instead.

Even though the ILogEntry instances themselves are volatile, the values returned 
by the getFieldValues methods are safe to store or keep references to.

This design was chosen to ensure that long-running, high-volume log processing 
jobs avoided creating millions of garbage objects that would cause the host VM 
to trash on long GC cycles; slowing the log processing and increasing volatility 
in the VM (e.g. starving heap space from other processes running inside the same VM).


Usage
-----
The CloudFront Log Parser Java Library is built on a callback-based model of 
execution; more specifically, you create a LogParser instance and an 
implementation of ILogParserCallback to handle each parsed log line, then pass 
the callback and a raw InputStream pointing at the log file to LogParser.parse(…) 
and you can sit back and receive parsed log lines in your handler method.

Execution would look like this:

	LogParser parser = new LogParser();
	InputStream stream = null;
	
	parser.parse(stream, new ILogParserCallback() {
		public void logEntryParsed(ILogEntry entry) {
			String ip = new String(entry.getFieldValue("c-ip"));
			String file = new String(entry.getFieldValue("cs-uri-stem"));
			String bytes = new String(entry.getFieldValue("sc-bytes"));
	
			System.out.println("Client from " + ip + " downloaded " + file
					+ " using " + bytes + " bytes.");
		}
	});

To make the parser as efficient as possible, field values are always returned 
as char[] to avoid unnecessary String allocations. If you need Strings, they are 
easy to create.


Runtime Requirements
--------------------

1.	The Buzz Media common-lib (tbm-common-lib-<VER>.jar)
	http://www.thebuzzmedia.com/software/common-lib-common-java-utility-library/

2.	The Buzz Media common-pars-erlib (tbm-common-parser-lib-<VER>.jar)
	http://www.thebuzzmedia.com/software/common-parser-lib-common-parser-java-utility-library/
	

FAQ
---
* How come values aren't Strings?
	This was done for performance reasons. Not everyone reading the values out
	of log files want them as Strings; they may want to write them back out to
	another storage location immediately. We save on creating a ton of unused
	String instances by avoiding this automatic creation.
	
	If you need Strings, easy, just wrap the char[] in new String(value);
	


History
-------
After deploying apps that utilized CloudFront for content delivery, I had the
need to parse the resulting access logs to get an idea of what kind of traffic,
bandwidth and access patterns the content was receiving.

Amazon promotes the use of their Map/Reduce Hadoop-based log parser multiple 
times on their site, but that requires additional EC2 charges to run.

After about a week of prototyping and engineering I had initial versions of the
CloudFront Log Parser written and running. Initial "does it work" prototypes took
an afternoon, but I toyed with a multitude of different API designs and 
approaches trying to best balance an easy-to-use API with runtime performance.

Eventually settling on what was by far the cleanest and simplest API, I used
HPROF to tighten up the runtime performance and minimize object creation down to
the bare minimum.

I hope this helps folks out there.


Contact
-------
If you have questions, comments or bug reports for this software please contact
us at: software@thebuzzmedia.com